# awesome-robust-depth-estimation [![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)
A curated list of awesome robust depth estimation papers, inspired by [awesome-NeRF](https://github.com/awesome-NeRF/awesome-NeRF).


#### [How to submit a pull request?](https://github.com/hitcslj/awesome-robust-depth-estimation/blob/main/how-to-PR.md)


## Table of Contents

- [Survey](#survey) 
- [Papers](#papers)
- [Benchmarks and Datasets](#Benchmarks-and-Datasets)
- [Talks](#talks)
- [Implementations](#implementations)

## Survey

- TODO

## Papers

<details open>
<summary>monocular</summary>

- [Robust Monocular Depth Estimation under Challenging Conditions](https://md4all.github.io), Gasperini et al., ICCV 2023 | [github](https://github.com/md4all/md4all) | [bibtext](./citations/md4all.txt) 

</details>


## Benchmarks and Datasets
- TODO


## Talks
- TODO


## Implementations
- TODO


## License 
awesome robust depth estimation is released under the [MIT license](./LICENSE).

## Contact
Primary contact: hitcslj@stu.hit.edu.cn. You can also contact: 1909985972@qq.com.